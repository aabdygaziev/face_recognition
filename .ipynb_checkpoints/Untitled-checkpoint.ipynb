{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Algorithm with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will try to build face recognition algorithm that tells you who is in fron of the camera. To do that, we need sample of training data. For the simplicity, I used my own pictures, and dowloanded from internet pictures of GOT stars - Kit Harrington, and Lena Headey.\n",
    "\n",
    "This project is inspired from <a href='https://www.codingforentrepreneurs.com/'> codingforentrepreneurs youtube channel</a>.\n",
    "\n",
    "Before starting make sure that you have opencv installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "First, we need to train our model on sample traingin data so it can recognize faces later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "from _testcapi import DBL_MAX\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to data-set\n",
    "\n",
    "base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "image_dir = os.path.join(base_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our face-detection classifier\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# creating face recognizer \n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(\n",
    "    neighbors=8,\n",
    "    radius=1,\n",
    "    grid_x=8,\n",
    "    grid_y=8,\n",
    "    threshold=DBL_MAX\n",
    ")\n",
    "\n",
    "# captures frames from our webcamer (0). \n",
    "# 0 means your first webcamera\n",
    "cap = cv2.VideoCapture(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other types of face recognizer model such as FisherFaces, and Eigen Faces. You can learn more about them here on this <a href='https://github.com/rragundez/PyData/blob/master/notebooks_tutorial/03_Building_the_Recognition_Model.ipynb'>repo by Rodrigo Agundez</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download cascade classifier from <a href='https://github.com/opencv/opencv/tree/master/data/haarcascades'>opencv github repo</a>. There several haarcascade classifiers, but we need **'haarcascade_frontalface_default.xml'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's upload our data-set. We need to define labels, and traning data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_id = 0\n",
    "label_ids = {}\n",
    "y_labels = []\n",
    "x_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading data set\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"JPG\") or file.endswith(\"jpeg\"):\n",
    "            path = os.path.join(root, file)\n",
    "            label = os.path.basename(root).replace(\" \", \"-\").lower()\n",
    "            # print(label, path)\n",
    "            if label not in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[label]\n",
    "            \n",
    "            pil_image = Image.open(path).convert(\"L\")  # grayscale\n",
    "            size = (550, 550)\n",
    "            final_image = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            image_array = np.array(final_image, \"uint8\")\n",
    "            \n",
    "            faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.5, minNeighbors=5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                roi = image_array[y:y + h, x:x + w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels as pickle file\n",
    "with open('labels.pickle', 'wb') as f:\n",
    "    pickle.dump(label_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save('trainer.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have finished building and training our model. Next, we will write our face detection algorithm. We saved our trained model as '**trainer.yml**'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: all of this codes are writen on PyCharm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# window size\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 500)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 250)\n",
    "cap.set(cv2.CAP_PROP_FPS, 25)\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainer.yml')\n",
    "\n",
    "\n",
    "with open('labels.pickle', 'rb') as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    labels = {v: k for k, v in og_labels.items()}\n",
    "\n",
    "while True:\n",
    "    # capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=2,\n",
    "        minNeighbors=5\n",
    "    )\n",
    "    for (x, y, w, h) in faces:\n",
    "        # print(x, y, w, h)\n",
    "        # roi stands for 'region of interest'\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # recognize?\n",
    "        id_, conf = recognizer.predict(roi_gray)\n",
    "        if 45 <= conf <= 85:\n",
    "            print(id_)\n",
    "            print(labels[id_])\n",
    "            font = cv2.FONT_HERSHEY_PLAIN\n",
    "            name = labels[id_]\n",
    "            color = (255, 255, 255)\n",
    "            stroke = 1\n",
    "            cv2.putText(\n",
    "                frame, name,\n",
    "                (x, y), font,\n",
    "                1, color,\n",
    "                stroke, cv2.LINE_AA)\n",
    "        # save img\n",
    "        img_item = 'my_image.png'\n",
    "        cv2.imwrite(img_item, roi_gray)\n",
    "\n",
    "        # draw rectangle\n",
    "        # BGR color\n",
    "        color = (255, 0, 0)\n",
    "        stroke = 2\n",
    "        end_cord_x = x + w\n",
    "        end_cord_y = y + h\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (x, y),\n",
    "            (end_cord_x, end_cord_y),\n",
    "            color,\n",
    "            stroke\n",
    "        )\n",
    "    # Display the resulting time\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is working, but it's not identifing a person correctly. The reason is data. I have very small data set, and quality of pictures also  affecting the model. You can work with this model and try it. It's fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
